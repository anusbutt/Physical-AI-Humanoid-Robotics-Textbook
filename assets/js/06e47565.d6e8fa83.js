"use strict";(globalThis.webpackChunkbook_source=globalThis.webpackChunkbook_source||[]).push([[7293],{1586:s=>{s.exports=JSON.parse('{"tag":{"label":"sensors","permalink":"/hackathon-phase-01/docs/tags/sensors","allTagsPath":"/hackathon-phase-01/docs/tags","count":7,"items":[{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project","title":"Capstone Project: Design a Multi-Sensor Humanoid Perception System","description":"Integrative project combining camera systems, depth sensing, IMU integration, and sensor fusion to design a complete perception system for a humanoid warehouse robot.","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems","title":"Lesson 1: Camera Systems and Computer Vision","description":"What Is a Camera in Robotics?","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing","title":"Lesson 2: Depth Sensing Technologies","description":"What Is Depth Sensing in Robotics?","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception","title":"Lesson 3: IMU and Proprioception for Humanoid Robots","description":"Learn how inertial measurement units and proprioceptive sensors enable humanoid robots to sense their own motion, orientation, and body position for dynamic balance control and spatial self-awareness.","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion","title":"Lesson 4: Sensor Fusion Techniques for Humanoid Robots","description":"Learn how sensor fusion combines camera, depth, and IMU data to create robust perception systems that overcome individual sensor limitations through complementary filtering, Kalman filtering, and Visual-Inertial Odometry.","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.summary","title":"Module 2 Capstone Summary: Integrated Sensor System Design","description":"Key takeaways and summary of the integrated sensor system design capstone project for humanoid robots.","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.summary"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/quiz","title":"Module 2 Quiz: Sensors and Perception for Humanoid Robots","description":"Assessment quiz covering camera systems, depth sensing, IMU sensors, and sensor fusion for humanoid robots. 15 questions testing comprehension across all four lessons. Passing score: 12/18 points (67%).","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/quiz"}],"unlisted":false}}')}}]);