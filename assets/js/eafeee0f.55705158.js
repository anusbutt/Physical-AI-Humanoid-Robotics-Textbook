"use strict";(globalThis.webpackChunkbook_source=globalThis.webpackChunkbook_source||[]).push([[5090],{2982:o=>{o.exports=JSON.parse('{"tag":{"label":"humanoid-robotics","permalink":"/hackathon-phase-01/docs/tags/humanoid-robotics","allTagsPath":"/hackathon-phase-01/docs/tags","count":3,"items":[{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems","title":"Lesson 1: Camera Systems and Computer Vision","description":"What Is a Camera in Robotics?","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception","title":"Lesson 3: IMU and Proprioception for Humanoid Robots","description":"Learn how inertial measurement units and proprioceptive sensors enable humanoid robots to sense their own motion, orientation, and body position for dynamic balance control and spatial self-awareness.","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception"},{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion","title":"Lesson 4: Sensor Fusion Techniques for Humanoid Robots","description":"Learn how sensor fusion combines camera, depth, and IMU data to create robust perception systems that overcome individual sensor limitations through complementary filtering, Kalman filtering, and Visual-Inertial Odometry.","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion"}],"unlisted":false}}')}}]);