<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Physical-AI-Humanoid-Robotics/vision-language-action/quiz" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Module 4 Quiz - Vision-Language-Action (VLA) | Physical AI &amp; Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://anusbutt.github.io/hackathon-phase-01/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://anusbutt.github.io/hackathon-phase-01/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Module 4 Quiz - Vision-Language-Action (VLA) | Physical AI &amp; Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="Instructions"><meta data-rh="true" property="og:description" content="Instructions"><link data-rh="true" rel="icon" href="/hackathon-phase-01/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz"><link data-rh="true" rel="alternate" href="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz" hreflang="en"><link data-rh="true" rel="alternate" href="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Physical AI & Humanoid Robotics","item":"https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"},{"@type":"ListItem","position":2,"name":"Module 4: Vision-Language-Action (VLA)","item":"https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/"},{"@type":"ListItem","position":3,"name":"Module 4 Quiz - Vision-Language-Action (VLA)","item":"https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz"}]}</script><link rel="alternate" type="application/rss+xml" href="/hackathon-phase-01/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics Textbook RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/hackathon-phase-01/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Textbook Atom Feed"><link rel="stylesheet" href="/hackathon-phase-01/assets/css/styles.5903934b.css">
<script src="/hackathon-phase-01/assets/js/runtime~main.94161a1c.js" defer="defer"></script>
<script src="/hackathon-phase-01/assets/js/main.ab534ac3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/hackathon-phase-01/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/hackathon-phase-01/"><div class="navbar__logo"><img src="/hackathon-phase-01/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/hackathon-phase-01/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics Textbook</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/anusbutt/hackathon-phase-01" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"><span title="Physical AI &amp; Humanoid Robotics" class="categoryLinkLabel_W154">Physical AI &amp; Humanoid Robotics</span></a><button aria-label="Collapse sidebar category &#x27;Physical AI &amp; Humanoid Robotics&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a><button aria-label="Expand sidebar category &#x27;Module 1: The Robotic Nervous System (ROS 2)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/"><span title="Module 2: Sensors and Perception for Humanoid Robots" class="categoryLinkLabel_W154">Module 2: Sensors and Perception for Humanoid Robots</span></a><button aria-label="Expand sidebar category &#x27;Module 2: Sensors and Perception for Humanoid Robots&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)</span></a><button aria-label="Expand sidebar category &#x27;Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a><button aria-label="Collapse sidebar category &#x27;Module 4: Vision-Language-Action (VLA)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action"><span title="Lesson 1 - Voice-to-Action Systems" class="linkLabel_WmDU">Lesson 1 - Voice-to-Action Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action.summary"><span title="Summary - Lesson 1 - Voice-to-Action Systems" class="linkLabel_WmDU">Summary - Lesson 1 - Voice-to-Action Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning"><span title="Lesson 2 - Cognitive Planning with LLMs" class="linkLabel_WmDU">Lesson 2 - Cognitive Planning with LLMs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning.summary"><span title="Summary - Lesson 2 - Cognitive Planning with LLMs" class="linkLabel_WmDU">Summary - Lesson 2 - Cognitive Planning with LLMs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration"><span title="Lesson 3 - Vision-Language Integration" class="linkLabel_WmDU">Lesson 3 - Vision-Language Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration.summary"><span title="Summary - Lesson 3 - Vision-Language Integration" class="linkLabel_WmDU">Summary - Lesson 3 - Vision-Language Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control"><span title="Lesson 4 - Action Execution and Control" class="linkLabel_WmDU">Lesson 4 - Action Execution and Control</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control.summary"><span title="Summary - Lesson 4 - Action Execution and Control" class="linkLabel_WmDU">Summary - Lesson 4 - Action Execution and Control</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project"><span title="Capstone Project - The Autonomous Humanoid" class="linkLabel_WmDU">Capstone Project - The Autonomous Humanoid</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project.summary"><span title="Summary - Capstone Project - The Autonomous Humanoid" class="linkLabel_WmDU">Summary - Capstone Project - The Autonomous Humanoid</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz"><span title="Module 4 Quiz - Vision-Language-Action (VLA)" class="linkLabel_WmDU">Module 4 Quiz - Vision-Language-Action (VLA)</span></a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/hackathon-phase-01/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"><span>Physical AI &amp; Humanoid Robotics</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/"><span>Module 4: Vision-Language-Action (VLA)</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Module 4 Quiz - Vision-Language-Action (VLA)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Module 4 Quiz: Vision-Language-Action (VLA)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="instructions">Instructions<a href="#instructions" class="hash-link" aria-label="Direct link to Instructions" title="Direct link to Instructions" translate="no">â€‹</a></h2>
<p>This quiz assesses your understanding of Vision-Language-Action (VLA) systems. The quiz contains 18 questions covering all aspects of VLA: voice-to-action systems, cognitive planning with LLMs, vision-language integration, and action execution. To pass, you must score at least 80% (14 out of 18 questions correct).</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-1-4-voice-to-action-systems-lesson-1">Questions 1-4: Voice-to-Action Systems (Lesson 1)<a href="#questions-1-4-voice-to-action-systems-lesson-1" class="hash-link" aria-label="Direct link to Questions 1-4: Voice-to-Action Systems (Lesson 1)" title="Direct link to Questions 1-4: Voice-to-Action Systems (Lesson 1)" translate="no">â€‹</a></h2>
<ol>
<li class="">
<p><strong>Multiple Choice</strong>: What is the primary purpose of audio preprocessing in a VLA system?</p>
<ul>
<li class="">A) To increase the volume of the audio signal</li>
<li class="">B) To optimize audio quality for speech recognition accuracy</li>
<li class="">C) To compress the audio for faster transmission</li>
<li class="">D) To convert audio to text format</li>
</ul>
</li>
<li class="">
<p><strong>Multiple Choice</strong>: Which of the following is NOT a key component of a voice-to-action system?</p>
<ul>
<li class="">A) Speech recognition engine</li>
<li class="">B) Natural language understanding module</li>
<li class="">C) Computer vision processor</li>
<li class="">D) Action execution system</li>
</ul>
</li>
<li class="">
<p><strong>Short Answer</strong>: Explain the role of confidence scoring in voice recognition systems and why it&#x27;s important for robotic applications.</p>
</li>
<li class="">
<p><strong>Short Answer</strong>: Describe the main challenges of implementing speech recognition in robotic environments compared to consumer applications.</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-5-8-cognitive-planning-with-llms-lesson-2">Questions 5-8: Cognitive Planning with LLMs (Lesson 2)<a href="#questions-5-8-cognitive-planning-with-llms-lesson-2" class="hash-link" aria-label="Direct link to Questions 5-8: Cognitive Planning with LLMs (Lesson 2)" title="Direct link to Questions 5-8: Cognitive Planning with LLMs (Lesson 2)" translate="no">â€‹</a></h2>
<ol start="5">
<li class="">
<p><strong>Multiple Choice</strong>: What does &quot;Chain-of-Thought&quot; prompting refer to in the context of LLM-based cognitive planning?</p>
<ul>
<li class="">A) A technique to make LLMs think step-by-step before providing answers</li>
<li class="">B) A method to chain multiple LLMs together</li>
<li class="">C) A way to reduce the computational cost of LLMs</li>
<li class="">D) A technique to improve the speed of LLM processing</li>
</ul>
</li>
<li class="">
<p><strong>Multiple Choice</strong>: Which of the following is a key principle of task decomposition in cognitive planning?</p>
<ul>
<li class="">A) Breaking complex tasks into hierarchical subtasks</li>
<li class="">B) Executing all tasks in parallel for efficiency</li>
<li class="">C) Minimizing the number of required sensors</li>
<li class="">D) Reducing the robot&#x27;s mobility requirements</li>
</ul>
</li>
<li class="">
<p><strong>Short Answer</strong>: Describe how an LLM might decompose the command &quot;Clean the living room&quot; into executable robotic actions.</p>
</li>
<li class="">
<p><strong>Scenario-Based</strong>: A user says &quot;Set up for a meeting&quot; to a humanoid robot. What clarifying questions might the robot need to ask, and why are they important for successful task execution?</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-9-12-vision-language-integration-lesson-3">Questions 9-12: Vision-Language Integration (Lesson 3)<a href="#questions-9-12-vision-language-integration-lesson-3" class="hash-link" aria-label="Direct link to Questions 9-12: Vision-Language Integration (Lesson 3)" title="Direct link to Questions 9-12: Vision-Language Integration (Lesson 3)" translate="no">â€‹</a></h2>
<ol start="9">
<li class="">
<p><strong>Multiple Choice</strong>: What is object grounding in vision-language integration?</p>
<ul>
<li class="">A) Connecting linguistic references to specific visual entities</li>
<li class="">B) Grounding the robot to prevent electrical hazards</li>
<li class="">C) Connecting the robot to the internet</li>
<li class="">D) Calibrating the robot&#x27;s sensors</li>
</ul>
</li>
<li class="">
<p><strong>Multiple Choice</strong>: Which vision-language model is known for learning visual concepts from natural language descriptions?</p>
<ul>
<li class="">A) GPT-3</li>
<li class="">B) CLIP</li>
<li class="">C) Whisper</li>
<li class="">D) DALL-E</li>
</ul>
</li>
<li class="">
<p><strong>Short Answer</strong>: Explain how a vision-language system would handle the command &quot;the red cup on the left&quot; when multiple red cups are visible in the scene.</p>
</li>
<li class="">
<p><strong>Scenario-Based</strong>: Describe the challenges a vision-language system faces when trying to identify &quot;the big book&quot; in a scene with multiple books of similar size. How might the system resolve this ambiguity?</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-13-15-action-execution-and-control-lesson-4">Questions 13-15: Action Execution and Control (Lesson 4)<a href="#questions-13-15-action-execution-and-control-lesson-4" class="hash-link" aria-label="Direct link to Questions 13-15: Action Execution and Control (Lesson 4)" title="Direct link to Questions 13-15: Action Execution and Control (Lesson 4)" translate="no">â€‹</a></h2>
<ol start="13">
<li class="">
<p><strong>Multiple Choice</strong>: What is the primary role of ROS2 action servers in VLA systems?</p>
<ul>
<li class="">A) To store robot configuration data</li>
<li class="">B) To provide standardized interfaces for long-running tasks with feedback</li>
<li class="">C) To process voice commands</li>
<li class="">D) To perform computer vision tasks</li>
</ul>
</li>
<li class="">
<p><strong>Multiple Choice</strong>: Which of the following is NOT a key component of safety validation in VLA systems?</p>
<ul>
<li class="">A) Collision detection</li>
<li class="">B) Capability verification</li>
<li class="">C) Audio preprocessing</li>
<li class="">D) Context validation</li>
</ul>
</li>
<li class="">
<p><strong>Short Answer</strong>: Explain the importance of feedback control loops in VLA action execution and provide an example of how they might adapt to changing conditions.</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-16-18-integration-and-capstone-concepts">Questions 16-18: Integration and Capstone Concepts<a href="#questions-16-18-integration-and-capstone-concepts" class="hash-link" aria-label="Direct link to Questions 16-18: Integration and Capstone Concepts" title="Direct link to Questions 16-18: Integration and Capstone Concepts" translate="no">â€‹</a></h2>
<ol start="16">
<li class="">
<p><strong>Short Answer</strong>: Describe the complete VLA pipeline from voice command to robot action execution, highlighting the key integration points between components.</p>
</li>
<li class="">
<p><strong>Multiple Choice</strong>: Which of the following represents the correct sequence of processing in a VLA system?</p>
<ul>
<li class="">A) Action execution â†’ Cognitive planning â†’ Voice recognition â†’ Vision-language integration</li>
<li class="">B) Voice recognition â†’ Cognitive planning â†’ Vision-language integration â†’ Action execution</li>
<li class="">C) Vision-language integration â†’ Voice recognition â†’ Cognitive planning â†’ Action execution</li>
<li class="">D) Cognitive planning â†’ Voice recognition â†’ Vision-language integration â†’ Action execution</li>
</ul>
</li>
<li class="">
<p><strong>Scenario-Based</strong>: A humanoid robot receives the command &quot;Please bring me the blue water bottle from the kitchen.&quot; Describe how each component of the VLA system would contribute to fulfilling this request.</p>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="answer-key">Answer Key<a href="#answer-key" class="hash-link" aria-label="Direct link to Answer Key" title="Direct link to Answer Key" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-1-4-voice-to-action-systems">Questions 1-4: Voice-to-Action Systems<a href="#questions-1-4-voice-to-action-systems" class="hash-link" aria-label="Direct link to Questions 1-4: Voice-to-Action Systems" title="Direct link to Questions 1-4: Voice-to-Action Systems" translate="no">â€‹</a></h3>
<ol>
<li class="">B) To optimize audio quality for speech recognition accuracy</li>
<li class="">C) Computer vision processor</li>
<li class="">Confidence scoring indicates the reliability of speech recognition results. In robotics, commands with low confidence should trigger clarification requests rather than execution to prevent robots from acting on misrecognized commands, which could be dangerous or counterproductive.</li>
<li class="">Key challenges include robot-internal noise from motors and fans, acoustic reflections in indoor environments creating reverberation, and real-time processing requirements that differ from batch processing applications.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-5-8-cognitive-planning-with-llms">Questions 5-8: Cognitive Planning with LLMs<a href="#questions-5-8-cognitive-planning-with-llms" class="hash-link" aria-label="Direct link to Questions 5-8: Cognitive Planning with LLMs" title="Direct link to Questions 5-8: Cognitive Planning with LLMs" translate="no">â€‹</a></h3>
<ol start="5">
<li class="">A) A technique to make LLMs think step-by-step before providing answers</li>
<li class="">A) Breaking complex tasks into hierarchical subtasks</li>
<li class="">The LLM would decompose &quot;Clean the living room&quot; into subtasks like: navigate to living room, identify dirty items, categorize items (trash vs. misplaced), dispose of trash, return misplaced items to proper locations, verify cleanliness.</li>
<li class="">Clarifying questions might include: &quot;Where is the meeting?&quot;, &quot;What items are needed for the meeting?&quot;, &quot;Are there specific arrangements required?&quot;, &quot;Who will attend the meeting?&quot; These questions are important because &quot;setting up for a meeting&quot; is ambiguous without context.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-9-12-vision-language-integration">Questions 9-12: Vision-Language Integration<a href="#questions-9-12-vision-language-integration" class="hash-link" aria-label="Direct link to Questions 9-12: Vision-Language Integration" title="Direct link to Questions 9-12: Vision-Language Integration" translate="no">â€‹</a></h3>
<ol start="9">
<li class="">A) Connecting linguistic references to specific visual entities</li>
<li class="">B) CLIP</li>
<li class="">The system would use spatial reasoning to identify which red cup is positioned to the left relative to the speaker&#x27;s perspective or a reference point. It might consider additional context like distance from other objects to disambiguate.</li>
<li class="">The system might use additional context like &quot;the big book near the laptop&quot; or &quot;the big book on the table&quot; to resolve ambiguity. It could also ask for clarification like &quot;Do you mean the book on the left or the one on the right?&quot;</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-13-15-action-execution-and-control">Questions 13-15: Action Execution and Control<a href="#questions-13-15-action-execution-and-control" class="hash-link" aria-label="Direct link to Questions 13-15: Action Execution and Control" title="Direct link to Questions 13-15: Action Execution and Control" translate="no">â€‹</a></h3>
<ol start="13">
<li class="">B) To provide standardized interfaces for long-running tasks with feedback</li>
<li class="">C) Audio preprocessing</li>
<li class="">Feedback control loops allow the system to monitor execution progress and adapt to changing conditions. For example, if a planned navigation path becomes blocked by a moving obstacle, the feedback loop would detect this and trigger replanning to find an alternative route.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="questions-16-18-integration-and-capstone-concepts-1">Questions 16-18: Integration and Capstone Concepts<a href="#questions-16-18-integration-and-capstone-concepts-1" class="hash-link" aria-label="Direct link to Questions 16-18: Integration and Capstone Concepts" title="Direct link to Questions 16-18: Integration and Capstone Concepts" translate="no">â€‹</a></h3>
<ol start="16">
<li class="">The VLA pipeline starts with voice recognition converting speech to text, followed by cognitive planning using LLMs to decompose commands into action sequences, vision-language integration to ground language in visual entities, and action execution through ROS2 action servers with safety validation throughout.</li>
<li class="">B) Voice recognition â†’ Cognitive planning â†’ Vision-language integration â†’ Action execution</li>
<li class="">Voice recognition processes &quot;Please bring me the blue water bottle from the kitchen&quot;; cognitive planning decomposes this into navigation and manipulation tasks; vision-language integration identifies the blue water bottle in the kitchen scene; action execution orchestrates navigation to the kitchen, approach to the bottle, grasp, and return to the user.</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="grading-rubric">Grading Rubric<a href="#grading-rubric" class="hash-link" aria-label="Direct link to Grading Rubric" title="Direct link to Grading Rubric" translate="no">â€‹</a></h2>
<ul>
<li class="">Multiple Choice Questions (1, 2, 5, 6, 9, 10, 13, 14, 17): 1 point each</li>
<li class="">Short Answer Questions (3, 4, 7, 11, 15): 2 points each (1 point for key concept, 1 point for explanation)</li>
<li class="">Scenario-Based Questions (8, 12, 18): 3 points each (1 point for approach, 1 point for technical accuracy, 1 point for completeness)</li>
<li class="">Integration Questions (16): 2 points</li>
</ul>
<p><strong>Total Points</strong>: 18
<strong>Passing Score</strong>: 14/18 (80%)</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/quiz">quiz</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/vla">vla</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/assessment">assessment</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/robotics">robotics</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/13-Physical-AI-Humanoid-Robotics/04-vision-language-action/06-quiz.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project.summary"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Summary - Capstone Project - The Autonomous Humanoid</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#instructions" class="table-of-contents__link toc-highlight">Instructions</a></li><li><a href="#questions-1-4-voice-to-action-systems-lesson-1" class="table-of-contents__link toc-highlight">Questions 1-4: Voice-to-Action Systems (Lesson 1)</a></li><li><a href="#questions-5-8-cognitive-planning-with-llms-lesson-2" class="table-of-contents__link toc-highlight">Questions 5-8: Cognitive Planning with LLMs (Lesson 2)</a></li><li><a href="#questions-9-12-vision-language-integration-lesson-3" class="table-of-contents__link toc-highlight">Questions 9-12: Vision-Language Integration (Lesson 3)</a></li><li><a href="#questions-13-15-action-execution-and-control-lesson-4" class="table-of-contents__link toc-highlight">Questions 13-15: Action Execution and Control (Lesson 4)</a></li><li><a href="#questions-16-18-integration-and-capstone-concepts" class="table-of-contents__link toc-highlight">Questions 16-18: Integration and Capstone Concepts</a></li><li><a href="#answer-key" class="table-of-contents__link toc-highlight">Answer Key</a><ul><li><a href="#questions-1-4-voice-to-action-systems" class="table-of-contents__link toc-highlight">Questions 1-4: Voice-to-Action Systems</a></li><li><a href="#questions-5-8-cognitive-planning-with-llms" class="table-of-contents__link toc-highlight">Questions 5-8: Cognitive Planning with LLMs</a></li><li><a href="#questions-9-12-vision-language-integration" class="table-of-contents__link toc-highlight">Questions 9-12: Vision-Language Integration</a></li><li><a href="#questions-13-15-action-execution-and-control" class="table-of-contents__link toc-highlight">Questions 13-15: Action Execution and Control</a></li><li><a href="#questions-16-18-integration-and-capstone-concepts-1" class="table-of-contents__link toc-highlight">Questions 16-18: Integration and Capstone Concepts</a></li></ul></li><li><a href="#grading-rubric" class="table-of-contents__link toc-highlight">Grading Rubric</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/">Textbook</a></li><li class="footer__item"><a class="footer__link-item" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/">Module 1: ROS2</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/anusbutt/hackathon-phase-01" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://linkedin.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">X (Twitter)<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://instagram.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://panaversity.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Panaversity<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2026 Physical AI & Humanoid Robotics Textbook. Built for Panaversity Hackathon.</div></div></div></footer><button class="floatingChatButton__Uyc" aria-label="Open AI Assistant" title="Ask questions about Physical AI &amp; Humanoid Robotics"><span class="chatIcon_GGtK">ðŸ’¬</span><span class="chatLabel_InO3">AI Assistant</span></button></div>
</body>
</html>