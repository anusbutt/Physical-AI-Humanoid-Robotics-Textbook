<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Nodes, Topics, and Services | Physical AI &amp; Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://anusbutt.github.io/hackathon-phase-01/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://anusbutt.github.io/hackathon-phase-01/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Nodes, Topics, and Services | Physical AI &amp; Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="Learn how ROS2 nodes communicate through topics (pub/sub) and services (request/response), and understand when to use each communication pattern for coordinating robot behaviors."><meta data-rh="true" property="og:description" content="Learn how ROS2 nodes communicate through topics (pub/sub) and services (request/response), and understand when to use each communication pattern for coordinating robot behaviors."><link data-rh="true" rel="icon" href="/hackathon-phase-01/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services"><link data-rh="true" rel="alternate" href="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services" hreflang="en"><link data-rh="true" rel="alternate" href="https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Physical AI & Humanoid Robotics","item":"https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"},{"@type":"ListItem","position":2,"name":"Module 1: The Robotic Nervous System (ROS 2)","item":"https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/"},{"@type":"ListItem","position":3,"name":"Nodes, Topics, and Services","item":"https://anusbutt.github.io/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services"}]}</script><link rel="alternate" type="application/rss+xml" href="/hackathon-phase-01/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics Textbook RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/hackathon-phase-01/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Textbook Atom Feed"><link rel="stylesheet" href="/hackathon-phase-01/assets/css/styles.5903934b.css">
<script src="/hackathon-phase-01/assets/js/runtime~main.94161a1c.js" defer="defer"></script>
<script src="/hackathon-phase-01/assets/js/main.ab534ac3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/hackathon-phase-01/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/hackathon-phase-01/"><div class="navbar__logo"><img src="/hackathon-phase-01/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/hackathon-phase-01/img/logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics Textbook</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/anusbutt/hackathon-phase-01" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"><span title="Physical AI &amp; Humanoid Robotics" class="categoryLinkLabel_W154">Physical AI &amp; Humanoid Robotics</span></a><button aria-label="Collapse sidebar category &#x27;Physical AI &amp; Humanoid Robotics&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a><button aria-label="Collapse sidebar category &#x27;Module 1: The Robotic Nervous System (ROS 2)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals"><span title="ROS2 Fundamentals" class="linkLabel_WmDU">ROS2 Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals.summary"><span title="ROS2 Fundamentals - Summary" class="linkLabel_WmDU">ROS2 Fundamentals - Summary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services"><span title="Nodes, Topics, and Services" class="linkLabel_WmDU">Nodes, Topics, and Services</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services.summary"><span title="Nodes, Topics, and Services - Summary" class="linkLabel_WmDU">Nodes, Topics, and Services - Summary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge"><span title="Python rclpy Bridge" class="linkLabel_WmDU">Python rclpy Bridge</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge.summary"><span title="Python rclpy Bridge - Summary" class="linkLabel_WmDU">Python rclpy Bridge - Summary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics"><span title="URDF for Humanoid Robots" class="linkLabel_WmDU">URDF for Humanoid Robots</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics.summary"><span title="URDF for Humanoid Robots - Summary" class="linkLabel_WmDU">URDF for Humanoid Robots - Summary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project"><span title="Capstone Project: Design a Delivery Robot System" class="linkLabel_WmDU">Capstone Project: Design a Delivery Robot System</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project.summary"><span title="Capstone Project: Design a Delivery Robot System - Summary" class="linkLabel_WmDU">Capstone Project: Design a Delivery Robot System - Summary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/quiz"><span title="Module 1 Quiz: The Robotic Nervous System (ROS 2)" class="linkLabel_WmDU">Module 1 Quiz: The Robotic Nervous System (ROS 2)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/"><span title="Module 2: Sensors and Perception for Humanoid Robots" class="categoryLinkLabel_W154">Module 2: Sensors and Perception for Humanoid Robots</span></a><button aria-label="Expand sidebar category &#x27;Module 2: Sensors and Perception for Humanoid Robots&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)</span></a><button aria-label="Expand sidebar category &#x27;Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a><button aria-label="Expand sidebar category &#x27;Module 4: Vision-Language-Action (VLA)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/hackathon-phase-01/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"><span>Physical AI &amp; Humanoid Robotics</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/"><span>Module 1: The Robotic Nervous System (ROS 2)</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Nodes, Topics, and Services</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Nodes, Topics, and Services</h1></header>
<p>Mastering the communication patterns that enable robot components to coordinate effectively - understanding when to broadcast data (topics) vs. when to request specific actions (services).</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-are-nodes">What Are Nodes?<a href="#what-are-nodes" class="hash-link" aria-label="Direct link to What Are Nodes?" title="Direct link to What Are Nodes?" translate="no">‚Äã</a></h2>
<p>In ROS2, a <strong>node</strong> is an independent process responsible for a single, well-defined task within your robot system. Think of nodes as specialized workers in a factory: one worker (node) operates the camera, another processes vision data, another controls motors, and another plans paths. Each focuses on their expertise without needing to understand what others do internally.</p>
<p>Every node runs in its own process with isolated memory, which provides crucial fault isolation. If your vision processing node crashes due to a corrupted image, your balance control node keeps running, preventing your humanoid robot from falling. This independence is fundamental to building reliable robotic systems where individual component failures don&#x27;t cascade into total system failure.</p>
<p>Nodes communicate exclusively through well-defined interfaces‚Äîthey cannot directly access each other&#x27;s memory or call each other&#x27;s functions. This enforced separation might seem restrictive if you&#x27;re used to writing monolithic programs, but it&#x27;s what enables the modularity that makes complex robots possible. You can develop, test, and debug each node independently, then compose them into increasingly sophisticated systems.</p>
<p>The <strong>node lifecycle</strong> in ROS2 is straightforward: nodes initialize (set up their publishers, subscribers, and internal state), run their main loop (processing messages, publishing data, responding to requests), and shutdown cleanly when asked. This predictable lifecycle makes it easy to start and stop nodes dynamically‚Äîcrucial when you need to upgrade a single component without restarting your entire robot.</p>
<p>Nodes discover each other automatically through DDS, forming the <strong>ROS2 graph</strong>. When you launch a camera node and a vision processing node on the same network, they find each other without manual configuration. This automatic discovery extends across multiple computers, so your robot&#x27;s onboard Raspberry Pi running motor controllers can seamlessly communicate with a powerful desktop computer running deep learning inference.</p>
<p>What makes nodes powerful isn&#x27;t just their independence‚Äîit&#x27;s how they <strong>compose</strong>. A simple walking controller might be one node. Add a balance compensation node that subscribes to IMU data, and your robot handles uneven terrain. Add obstacle detection and path planning nodes, and now it navigates autonomously. Each capability is an independent module that integrates through standardized communication.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-node-communication-matters">Why Node Communication Matters<a href="#why-node-communication-matters" class="hash-link" aria-label="Direct link to Why Node Communication Matters" title="Direct link to Why Node Communication Matters" translate="no">‚Äã</a></h2>
<p>A humanoid robot must coordinate dozens of subsystems simultaneously: vision sensors feed object detection, which informs navigation planning, which commands leg actuators, while balance control monitors orientation and makes real-time adjustments. No single computer can efficiently handle all this computation, and even if it could, tightly coupling everything into one program would be an unmaintainable nightmare.</p>
<p><strong>The Coordination Challenge</strong>: Imagine trying to coordinate a humanoid&#x27;s walk cycle. The gait planner generates desired foot positions 10 times per second. The balance controller needs IMU data at 100Hz to maintain stability. Camera frames arrive at 30Hz. Motor controllers expect commands at 1000Hz for smooth motion. These different update rates must coexist without one blocking another. ROS2&#x27;s asynchronous communication patterns solve this through topics‚Äîeach node publishes data at its natural rate, and subscribers consume it at theirs.</p>
<p><strong>Data Flow vs. Commands</strong>: Not all robot communication is the same. A camera continuously broadcasts image data whether anyone is listening or not (data flow). But when you want your robot to grasp an object, you send a specific request and wait for confirmation that the grasp succeeded (command). Topics handle data flow; services handle commands. Choosing the wrong pattern leads to systems that work in demos but fail unpredictably in real environments.</p>
<p><strong>Reliability Requirements Vary</strong>: When your humanoid publishes its battery level, losing an occasional message is fine‚Äîthe next update arrives in a second. But when the safety system sends an emergency stop command, that message must arrive, guaranteed, exactly once. ROS2&#x27;s Quality of Service (QoS) policies let you tune this tradeoff per-topic: safety-critical commands get reliable delivery, high-frequency sensor data tolerates loss for lower latency.</p>
<p><strong>Distributed Intelligence</strong>: Modern humanoid robots often use multiple computers: embedded microcontrollers for motor control (real-time requirements), edge GPUs for vision processing (computation requirements), and cloud connectivity for learning and telemetry. ROS2&#x27;s communication patterns abstract away the physical network topology‚Äîwhether a subscriber is on the same computer or across WiFi, the programming model remains identical. This abstraction accelerates development and makes systems portable.</p>
<p><strong>Ecosystem Integration</strong>: When you use ROS2&#x27;s standard communication patterns, your robot automatically works with the entire ROS2 ecosystem. Visualization tools subscribe to your topics to display robot state. Data recording tools capture message streams for later analysis. Simulation systems can replace real sensors by publishing synthetic data to the same topics. This ecosystem effect multiplies as more developers follow the same patterns.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-principles">Key Principles<a href="#key-principles" class="hash-link" aria-label="Direct link to Key Principles" title="Direct link to Key Principles" translate="no">‚Äã</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="topics-publish-subscribe-many-to-many">Topics: Publish-Subscribe (Many-to-Many)<a href="#topics-publish-subscribe-many-to-many" class="hash-link" aria-label="Direct link to Topics: Publish-Subscribe (Many-to-Many)" title="Direct link to Topics: Publish-Subscribe (Many-to-Many)" translate="no">‚Äã</a></h3>
<p><strong>Topics are for continuous data streams</strong>: A topic is a named bus where nodes publish data and others subscribe to receive it. Publishers broadcast messages without knowing who (if anyone) is listening. Subscribers receive messages without knowing who published them. This <strong>loose coupling</strong> is essential for flexibility‚Äîyou can add new subscribers (like a data logger or visualizer) without modifying publishers.</p>
<p><strong>Asynchronous and non-blocking</strong>: When a node publishes to a topic, it doesn&#x27;t wait for subscribers to process the data. The publisher continues immediately, making topics perfect for high-frequency sensors (cameras, LiDAR, IMU) that can&#x27;t afford to block waiting for slow consumers. Subscribers process messages in callbacks that run independently of the publishing node&#x27;s timing.</p>
<p><strong>Many-to-many communication</strong>: Multiple nodes can publish to the same topic (sensor fusion from multiple cameras), and multiple nodes can subscribe (vision processing, obstacle detection, and recording all listening to camera data). This flexibility enables modular architectures where capabilities can be added or removed without restructuring the entire system.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="services-request-response-one-to-one">Services: Request-Response (One-to-One)<a href="#services-request-response-one-to-one" class="hash-link" aria-label="Direct link to Services: Request-Response (One-to-One)" title="Direct link to Services: Request-Response (One-to-One)" translate="no">‚Äã</a></h3>
<p><strong>Services are for explicit requests</strong>: Unlike topics where data flows continuously, a service represents an action a node can perform on request. Think of services like function calls across nodes: a client sends a request with parameters, the service processes it, and sends back a response. Common uses include requesting a robot&#x27;s current state, triggering a calibration routine, or commanding a discrete action.</p>
<p><strong>Synchronous and blocking</strong>: When a node calls a service, it waits (blocks) until the service responds or times out. This synchronous behavior is appropriate for operations that complete quickly and where the requester needs confirmation before proceeding. However, it&#x27;s dangerous for long-running operations‚Äîblocking for minutes while waiting for a &quot;navigate to waypoint&quot; service would freeze your node.</p>
<p><strong>One-to-one communication</strong>: Each service request goes to exactly one service server, and that server sends exactly one response back to the requester. While multiple nodes can call the same service, each call is an independent transaction. This pattern ensures predictable behavior for commands that require acknowledgment.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="quality-of-service-qos-policies">Quality of Service (QoS) Policies<a href="#quality-of-service-qos-policies" class="hash-link" aria-label="Direct link to Quality of Service (QoS) Policies" title="Direct link to Quality of Service (QoS) Policies" translate="no">‚Äã</a></h3>
<p><strong>Tuning reliability vs. performance</strong>: Every topic and service can specify QoS policies that control how messages are delivered. <strong>Reliable</strong> delivery guarantees messages arrive (like TCP), retransmitting if needed‚Äîessential for commands. <strong>Best effort</strong> delivery skips retransmission (like UDP), accepting occasional loss for lower latency‚Äîappropriate for high-frequency sensor data where the next reading is more valuable than a delayed old one.</p>
<p><strong>History depth and durability</strong>: QoS policies also control how many messages are buffered (<strong>history depth</strong>) and whether late-joining subscribers receive previous messages (<strong>durability</strong>). A robot state publisher might use &quot;transient local&quot; durability so new subscribers immediately receive the current state without waiting for the next publish cycle.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-ai-colearning-prompt">üí¨ AI Colearning Prompt<a href="#-ai-colearning-prompt" class="hash-link" aria-label="Direct link to üí¨ AI Colearning Prompt" title="Direct link to üí¨ AI Colearning Prompt" translate="no">‚Äã</a></h3>
<blockquote>
<p><strong>Suggested Exploration</strong>: Ask Claude or ChatGPT to explain when you should use topics vs. services for a robot arm control scenario. Specifically: &quot;I have a robot arm that needs to (1) report its current joint angles, (2) respond to commands to move to specific positions, and (3) send alerts when it detects excessive force. Should each of these use topics or services? Why?&quot;</p>
<p>Then extend the question: &quot;What happens if I use the wrong pattern‚Äîwhat problems would occur if joint angles were a service instead of a topic, or if position commands were a topic instead of a service?&quot;</p>
<p>This exploration will solidify your understanding of communication pattern selection.</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-expert-insight">üéì Expert Insight<a href="#-expert-insight" class="hash-link" aria-label="Direct link to üéì Expert Insight" title="Direct link to üéì Expert Insight" translate="no">‚Äã</a></h3>
<p><strong>Quality of Service: The Hidden Complexity That Matters</strong></p>
<p>QoS policies are where ROS2&#x27;s DDS foundation shows its power‚Äîand where beginners often stumble. Unlike ROS1 where communication was simple but inflexible, ROS2 lets you tune reliability, latency, and resource usage per-topic. This flexibility is crucial for production robots but adds complexity.</p>
<p><strong>The Reliability Tradeoff</strong>: Reliable QoS guarantees message delivery through acknowledgments and retransmission‚Äîperfect for commands where &quot;emergency stop&quot; must never be lost. But reliable delivery adds latency and network overhead. For a camera publishing 30 frames/second, missing one frame is better than delaying all subsequent frames waiting for a retransmit. Best-effort QoS accepts loss for lower latency‚Äîuse it for high-frequency sensor data.</p>
<p><strong>History Depth Matters</strong>: A depth-1 history keeps only the latest message in the queue. For a robot pose topic, only the current position matters‚Äîold positions are irrelevant. But for a command topic where a burst of commands might arrive faster than they&#x27;re processed, you need sufficient depth to buffer them. Too shallow and commands are dropped; too deep and you waste memory and might process stale commands.</p>
<p><strong>Compatibility Required</strong>: Here&#x27;s the catch‚Äîpublishers and subscribers must have compatible QoS policies or they won&#x27;t connect. A reliable publisher won&#x27;t match a best-effort subscriber (reliability mismatch). A depth-10 publisher won&#x27;t match a depth-1 subscriber with incompatible durability. These &quot;incompatible QoS&quot; errors are a common source of frustration when topics mysteriously don&#x27;t connect despite correct names.</p>
<p><strong>For beginners in 2025</strong>: Start with default QoS policies (reliable, volatile, depth-10) and only tune when you hit specific problems‚Äîcameras dropping frames due to network overhead, commands being lost, or excessive memory usage. The ROS2 Humble defaults are sensible for most use cases. As you gain experience, measure first, optimize second.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-example">Practical Example<a href="#practical-example" class="hash-link" aria-label="Direct link to Practical Example" title="Direct link to Practical Example" translate="no">‚Äã</a></h2>
<p>Let&#x27;s design the communication architecture for a humanoid robot performing a manipulation task: picking up a bottle from a table.</p>
<p><strong>The Scenario</strong>: Your humanoid has stereo cameras for vision, force sensors in its hands, arm joint controllers, and a central task planner. It must locate the bottle, reach for it, grasp with appropriate force, and confirm success.</p>
<p><strong>The Communication Architecture</strong>:</p>
<p><strong>Topics (Continuous Data Streams)</strong>:</p>
<ul>
<li class="">
<p><code>/camera/left/image</code> and <code>/camera/right/image</code> (sensor_msgs/Image, 30Hz): Camera nodes publish continuously. A vision processing node subscribes to detect the bottle&#x27;s 3D position. Uses <strong>best-effort</strong> QoS since missing a frame is acceptable‚Äîthe next one arrives in 33ms.</p>
</li>
<li class="">
<p><code>/hand/force_sensor</code> (geometry_msgs/WrenchStamped, 100Hz): Force sensors publish measured forces continuously. The grasp controller subscribes to detect when grip force is sufficient. Best-effort QoS, depth-1 history‚Äîonly current force matters.</p>
</li>
<li class="">
<p><code>/arm/joint_states</code> (sensor_msgs/JointState, 50Hz): Arm controllers publish current joint angles and velocities. Multiple subscribers (visualization, planning, telemetry) receive this data. Best-effort QoS‚Äîif visualization lags, it&#x27;s not safety-critical.</p>
</li>
<li class="">
<p><code>/task/status</code> (std_msgs/String, 1Hz): Task planner publishes current task phase (&quot;locating bottle&quot;, &quot;reaching&quot;, &quot;grasping&quot;). Used for monitoring and debugging. Reliable QoS with transient-local durability so late-joining monitors see current status immediately.</p>
</li>
</ul>
<p><strong>Services (Explicit Requests)</strong>:</p>
<ul>
<li class="">
<p><code>/vision/locate_object</code> (Request: object_name, Response: pose): When the task planner is ready to grasp, it calls this service asking vision processing to locate the bottle. The service responds with 3D coordinates or an error if the bottle isn&#x27;t visible. Blocks until response received (synchronous).</p>
</li>
<li class="">
<p><code>/arm/move_to_pose</code> (Request: target_pose, Response: success): Task planner requests arm movement to the grasp position. The service returns success when the arm reaches the target or fails on collision/timeout. This is synchronous because the planner must wait for the arm to reach before attempting the grasp.</p>
</li>
<li class="">
<p><code>/gripper/set_force</code> (Request: force_newtons, Response: acknowledged): Commands the gripper to apply specific grasping force. Returns immediately after the command is accepted (doesn&#x27;t wait for force to stabilize‚Äîthe continuous force sensor topic monitors that).</p>
</li>
</ul>
<p><strong>Why This Design Works</strong>: Notice how continuous sensor data flows through topics at natural rates without blocking anything. Commands that require confirmation (locate, move, grasp) use services so the task planner knows when each step completes before proceeding. If vision processing crashes mid-reach, force sensors and joint states keep publishing‚Äîthe arm continues its motion safely even though planning halted. When vision restarts, it reconnects automatically via DDS discovery.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="-practice-exercise">ü§ù Practice Exercise<a href="#-practice-exercise" class="hash-link" aria-label="Direct link to ü§ù Practice Exercise" title="Direct link to ü§ù Practice Exercise" translate="no">‚Äã</a></h3>
<p><strong>Design Communication Patterns for a Delivery Robot</strong></p>
<p>You&#x27;re building an autonomous delivery robot for indoor environments. It has:</p>
<ul>
<li class="">LIDAR scanner for obstacle detection (360¬∞ scan, 10Hz)</li>
<li class="">IMU for orientation tracking (100Hz)</li>
<li class="">Wheel encoders for position estimation (50Hz)</li>
<li class="">Navigation planner that computes paths</li>
<li class="">Motor controllers for left/right wheels</li>
<li class="">Delivery status indicator (LED display)</li>
<li class="">User interface where staff request deliveries</li>
</ul>
<p><strong>Your Task</strong>: For each of the following, decide if it should be a <strong>topic</strong> or a <strong>service</strong>, and justify your choice:</p>
<ol>
<li class="">LIDAR scan data being sent to the obstacle detection system</li>
<li class="">Staff requesting &quot;deliver to Room 302&quot;</li>
<li class="">Navigation planner commanding wheel velocities</li>
<li class="">Robot reporting its current battery level</li>
<li class="">Emergency stop command from a safety monitor</li>
<li class="">Request to the navigation system: &quot;What&#x27;s your current estimated position?&quot;</li>
</ol>
<p>For each, consider:</p>
<ul>
<li class="">Is it continuous data or a one-time request?</li>
<li class="">Does the sender need acknowledgment/response?</li>
<li class="">What happens if a message is lost?</li>
<li class="">How often does this communication occur?</li>
</ul>
<p>Write out your answers, then ask an AI assistant to review your reasoning. Understanding these tradeoffs is crucial for designing robust robot systems.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">‚Äã</a></h2>
<p><strong>Key Takeaways</strong>:</p>
<ul>
<li class="">
<p><strong>Nodes are independent processes</strong>: Each node handles one responsibility with isolated memory and predictable lifecycle. This independence enables modular development, fault isolation, and dynamic composition of robot capabilities.</p>
</li>
<li class="">
<p><strong>Topics for data streams, services for commands</strong>: Topics use pub/sub for continuous, asynchronous data flow (sensors, state updates). Services use request/response for explicit commands that require acknowledgment (actions, queries, discrete operations).</p>
</li>
<li class="">
<p><strong>Communication patterns have tradeoffs</strong>: Topics are asynchronous (non-blocking, many-to-many, lossy unless QoS configured otherwise). Services are synchronous (blocking, one-to-one, reliable). Choose based on your use case‚Äîcontinuous vs. discrete, timing requirements, reliability needs.</p>
</li>
<li class="">
<p><strong>Quality of Service policies tune behavior</strong>: QoS settings control reliability (guaranteed vs. best-effort), history (buffer depth), and durability (late-joiner behavior). Default settings work for most cases; tune when you hit specific problems with latency, reliability, or resource usage.</p>
</li>
<li class="">
<p><strong>Pattern selection impacts system behavior</strong>: Using the wrong pattern causes subtle failures‚Äîservices that block too long, topics that lose critical commands, mismatched QoS preventing connections. Design communication architecture early and validate it matches your operational requirements.</p>
</li>
</ul>
<p><strong>What You Should Now Understand</strong>: You can now explain how ROS2 nodes communicate through topics and services, choose the appropriate pattern for different robot scenarios, and understand why communication architecture design is foundational to reliable robotic systems. You&#x27;re ready to see these concepts implemented in actual Python code in the next lesson.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">‚Äã</a></h2>
<p>You&#x27;ve learned <strong>how</strong> robot components communicate through topics and services. In the next lesson, &quot;Python rclpy Bridge,&quot; we&#x27;ll translate these concepts into <strong>working code</strong>. You&#x27;ll see how to create nodes in Python, set up publishers and subscribers, define service clients and servers, and bring these communication patterns to life in the <code>rclpy</code> library.</p>
<p>This progression from conceptual understanding to hands-on implementation mirrors professional robotics development: first master the architecture and patterns, then implement them with confidence knowing why each design choice matters. With communication patterns solid, you&#x27;ll write robot code that&#x27;s maintainable, testable, and composable.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/ros-2">ros2</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/nodes">nodes</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/topics">topics</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/services">services</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/communication">communication</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/pub-sub">pub-sub</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/request-response">request-response</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/hackathon-phase-01/docs/tags/qos">qos</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/13-Physical-AI-Humanoid-Robotics/01-ros2-nervous-system/02-nodes-topics-services.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals.summary"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">ROS2 Fundamentals - Summary</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services.summary"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Nodes, Topics, and Services - Summary</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-are-nodes" class="table-of-contents__link toc-highlight">What Are Nodes?</a></li><li><a href="#why-node-communication-matters" class="table-of-contents__link toc-highlight">Why Node Communication Matters</a></li><li><a href="#key-principles" class="table-of-contents__link toc-highlight">Key Principles</a><ul><li><a href="#topics-publish-subscribe-many-to-many" class="table-of-contents__link toc-highlight">Topics: Publish-Subscribe (Many-to-Many)</a></li><li><a href="#services-request-response-one-to-one" class="table-of-contents__link toc-highlight">Services: Request-Response (One-to-One)</a></li><li><a href="#quality-of-service-qos-policies" class="table-of-contents__link toc-highlight">Quality of Service (QoS) Policies</a></li><li><a href="#-ai-colearning-prompt" class="table-of-contents__link toc-highlight">üí¨ AI Colearning Prompt</a></li><li><a href="#-expert-insight" class="table-of-contents__link toc-highlight">üéì Expert Insight</a></li></ul></li><li><a href="#practical-example" class="table-of-contents__link toc-highlight">Practical Example</a><ul><li><a href="#-practice-exercise" class="table-of-contents__link toc-highlight">ü§ù Practice Exercise</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/">Textbook</a></li><li class="footer__item"><a class="footer__link-item" href="/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/">Module 1: ROS2</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/anusbutt/hackathon-phase-01" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://linkedin.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">X (Twitter)<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://instagram.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://panaversity.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Panaversity<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2026 Physical AI & Humanoid Robotics Textbook. Built for Panaversity Hackathon.</div></div></div></footer><button class="floatingChatButton__Uyc" aria-label="Open AI Assistant" title="Ask questions about Physical AI &amp; Humanoid Robotics"><span class="chatIcon_GGtK">üí¨</span><span class="chatLabel_InO3">AI Assistant</span></button></div>
</body>
</html>