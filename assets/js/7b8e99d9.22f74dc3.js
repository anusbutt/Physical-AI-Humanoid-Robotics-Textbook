"use strict";(globalThis.webpackChunkbook_source=globalThis.webpackChunkbook_source||[]).push([[3298],{3697:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary","title":"Summary: Lesson 3 - IMU and Proprioception","description":"Module: Module 2 - Sensors and Perception for Humanoid Robots","source":"@site/docs/13-Physical-AI-Humanoid-Robotics/02-sensors-perception/03-imu-proprioception.summary.md","sourceDirName":"13-Physical-AI-Humanoid-Robotics/02-sensors-perception","slug":"/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/13-Physical-AI-Humanoid-Robotics/02-sensors-perception/03-imu-proprioception.summary.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"IMU & Proprioception","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception"},"next":{"title":"Sensor Fusion","permalink":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion"}}');var r=s(4848),o=s(8453);const t={},l="Summary: Lesson 3 - IMU and Proprioception",c={},a=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Key Concepts Covered",id:"key-concepts-covered",level:2},{value:"IMU Sensor Components (Section 3.1)",id:"imu-sensor-components-section-31",level:3},{value:"Sensor Drift and Noise (Section 3.2)",id:"sensor-drift-and-noise-section-32",level:3},{value:"sensor_msgs/Imu Message Structure (Section 3.3)",id:"sensor_msgsimu-message-structure-section-33",level:3},{value:"Proprioception - Robot Body Awareness (Section 3.4)",id:"proprioception---robot-body-awareness-section-34",level:3},{value:"Balance Control Loop (Section 3.5)",id:"balance-control-loop-section-35",level:3},{value:"Real-World Examples",id:"real-world-examples",level:2},{value:"Boston Dynamics Atlas",id:"boston-dynamics-atlas",level:3},{value:"Agility Robotics Digit",id:"agility-robotics-digit",level:3},{value:"Unitree H1",id:"unitree-h1",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Example 1: Balance State Monitoring (73 lines)",id:"example-1-balance-state-monitoring-73-lines",level:3},{value:"Example 2: Fall Detection Algorithm (180 lines)",id:"example-2-fall-detection-algorithm-180-lines",level:3},{value:"Practice Exercises",id:"practice-exercises",level:2},{value:"Common Pitfalls (Expert Insights)",id:"common-pitfalls-expert-insights",level:2},{value:"Assessment Criteria",id:"assessment-criteria",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Metadata",id:"metadata",level:2},{value:"Validation Status",id:"validation-status",level:2},{value:"Technical Corrections Applied",id:"technical-corrections-applied",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"summary-lesson-3---imu-and-proprioception",children:"Summary: Lesson 3 - IMU and Proprioception"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Module"}),": Module 2 - Sensors and Perception for Humanoid Robots\r\n",(0,r.jsx)(n.strong,{children:"Lesson"}),": 03-imu-proprioception.md\r\n",(0,r.jsx)(n.strong,{children:"Target Audience"}),": CS students with Python + Module 1 (ROS2) + Lessons 1-2 (Camera Systems, Depth Sensing) knowledge\r\n",(0,r.jsx)(n.strong,{children:"Estimated Time"}),": 45-55 minutes\r\n",(0,r.jsx)(n.strong,{children:"Difficulty"}),": Beginner-Intermediate"]}),"\n",(0,r.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this lesson, students will be able to:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Understand"})," how IMU sensors (accelerometer, gyroscope, magnetometer) measure motion and orientation for humanoid balance control"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Apply"})," knowledge of sensor_msgs/Imu message structure to subscribe to and process inertial data in ROS2"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analyze"})," the trade-offs between sensor drift, noise, and long-term accuracy for accelerometers, gyroscopes, and magnetometers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Evaluate"})," proprioceptive sensor integration (IMU + joint encoders) for whole-body state awareness in humanoid robots"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Create"})," balance monitoring and fall detection systems using real-time IMU feedback loops"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"key-concepts-covered",children:"Key Concepts Covered"}),"\n",(0,r.jsx)(n.h3,{id:"imu-sensor-components-section-31",children:"IMU Sensor Components (Section 3.1)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Three Sensor Types"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Accelerometer"}),": Measures linear acceleration in m/s\xb2, always includes gravity (9.81 m/s\xb2 when stationary), detects tilt and linear motion"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gyroscope"}),": Measures angular velocity in rad/s, precise short-term but suffers from drift (0.1-1\xb0/hour consumer-grade, 1-3\xb0/hour tactical-grade)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Magnetometer"}),": Measures magnetic field direction in \u03bcT, provides absolute heading reference but sensitive to electromagnetic interference"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Measurement Characteristics"}),": Each sensor has distinct strengths (accelerometer = long-term gravity reference, gyroscope = short-term precision, magnetometer = absolute direction) and weaknesses (noise, drift, interference)"]}),"\n",(0,r.jsx)(n.h3,{id:"sensor-drift-and-noise-section-32",children:"Sensor Drift and Noise (Section 3.2)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Accelerometer Noise"}),": High-frequency vibrations from motors/footsteps, but reliable long-term due to gravity reference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gyroscope Drift"}),": Accumulates over time (24\xb0 after 1 day at 1\xb0/hour), requires continuous recalibration from other sensors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Magnetometer Interference"}),": Distorted by motors, metal, electronics; unreliable indoors but provides absolute heading"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Insight"}),": No single sensor is perfect; sensor fusion combines strengths while compensating for individual weaknesses"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sensor_msgsimu-message-structure-section-33",children:"sensor_msgs/Imu Message Structure (Section 3.3)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ROS2 Message Fields"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"header"}),": timestamp + frame_id for coordinate transformations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"orientation"}),": Quaternion (x, y, z, w) avoiding gimbal lock - compact 3D rotation representation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"angular_velocity"}),": Vector3 (rad/s) from gyroscope"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"linear_acceleration"}),": Vector3 (m/s\xb2) from accelerometer, includes gravity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"covariance matrices"}),": 9-element arrays encoding measurement uncertainty for sensor fusion algorithms"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Typical Publishing"}),": 100-500 Hz update rates on /imu/data topic"]}),"\n",(0,r.jsx)(n.h3,{id:"proprioception---robot-body-awareness-section-34",children:"Proprioception - Robot Body Awareness (Section 3.4)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": Internal sense of body position and motion without external observation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implementation"}),": IMU (torso orientation/acceleration) + joint encoders (limb angles) = complete 3D body state"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Distinction from Vision"}),": Proprioception works in darkness, at high frequency (100+ Hz), with low latency; vision provides external perception"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Applications"}),": Balance during reaching, foot placement while walking, reaction to external pushes"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"balance-control-loop-section-35",children:"Balance Control Loop (Section 3.5)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Four-Stage Closed Loop"})," (10-50ms cycle):"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sense"}),": IMU detects tilt angle and rotation rate"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compute"}),": Controller determines corrective action"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Act"}),": Motor commands adjust joints"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Repeat"}),": Continuous feedback at 200 Hz"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Three Balance Strategies"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ankle Strategy"}),": Tilt <5\xb0 - Rotate ankles to shift center of pressure (fastest, most efficient)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hip Strategy"}),": Tilt 5-15\xb0 - Bend at hips for larger body movements (more powerful)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stepping Strategy"}),": Tilt >15\xb0 - Take recovery step to catch fall (last resort, most complex)"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Reaction Time"}),": 25-50ms sensor-to-actuation loop, faster than human reaction time (~200ms)"]}),"\n",(0,r.jsx)(n.h2,{id:"real-world-examples",children:"Real-World Examples"}),"\n",(0,r.jsx)(n.h3,{id:"boston-dynamics-atlas",children:"Boston Dynamics Atlas"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor"}),": KVH 1750 tactical-grade IMU (Fiber Optic Gyroscope + MEMS accelerometer)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Specs"}),": 1-1000 Hz programmable rates, 2g/10g/30g accelerometer ranges, pelvis-mounted (9cm behind pelvis link, 45\xb0 rotation)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Application"}),": Acrobatic movements (parkour, backflips) requiring precision balance during high-impact landings"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Insight"}),": FOG-based IMU prioritizes precision over cost; sensor fusion with force sensors, LiDAR, stereo vision, and encoders achieves 95%+ balance stability through EKF algorithms"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"agility-robotics-digit",children:"Agility Robotics Digit"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor"}),": MEMS IMU with estimated specs (\xb14g accelerometer, \xb1500\xb0/s gyroscope) at 100-200 Hz (accel) / 200-500 Hz (gyro)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Platform"}),": 5'9\" bipedal robot for warehouse logistics, 28 DOF, 4-hour battery"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Application"}),": ZMP/CoP calculations for locomotion stability in dynamic environments"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Insight"}),": Sensor fusion reduces force estimation errors to ~5 N\xb7m; IMU integration with depth cameras and encoders improves pose estimation accuracy by ~30% vs encoder-only"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"unitree-h1",children:"Unitree H1"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Achievement"}),": Guinness World Record fastest humanoid (3.3 m/s), first electric humanoid standing backflip"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensors"}),": Real-time IMU + 3D LiDAR (Livox Mid-360) + RealSense D435 depth cameras + joint encoders + contact sensors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Specs"}),": 180cm, 47kg, up to 360 Nm joint torque"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Insight"}),": Sub-10ms sensor fusion loop enables rapid corrective torques for dynamic stability; IMU + 360\xb0 LiDAR creates proprioceptive-exteroceptive feedback allowing predictive balance adjustments before ground contact"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,r.jsx)(n.h3,{id:"example-1-balance-state-monitoring-73-lines",children:"Example 1: Balance State Monitoring (73 lines)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Functionality"}),": Subscribe to /imu/data, extract quaternion orientation, convert to roll/pitch angles, detect tilt >10\xb0 threshold"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Techniques"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quaternion-to-Euler conversion using ",(0,r.jsx)(n.code,{children:"math.atan2()"})," and ",(0,r.jsx)(n.code,{children:"math.asin()"})," formulas"]}),"\n",(0,r.jsx)(n.li,{children:"Type hints on all function signatures for Python 3.11+"}),"\n",(0,r.jsx)(n.li,{children:"Proper ROS2 node inheritance and callback patterns"}),"\n",(0,r.jsx)(n.li,{children:"Threshold-based decision logic for balance strategies"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Educational Value"}),": Demonstrates sensing-to-decision pipeline (IMU \u2192 ROS2 \u2192 callback \u2192 control decision)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-2-fall-detection-algorithm-180-lines",children:"Example 2: Fall Detection Algorithm (180 lines)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Functionality"}),": Detect freefall phase (acceleration <2.0 m/s\xb2 for >0.3s) and impact phase (acceleration >20.0 m/s\xb2)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Techniques"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["numpy vector magnitude calculation: ",(0,r.jsx)(n.code,{children:"np.linalg.norm(accel_vector)"})]}),"\n",(0,r.jsx)(n.li,{children:"State machine tracking freefall duration with ROS2 Time objects"}),"\n",(0,r.jsx)(n.li,{children:"Error handling with try-except blocks for robustness"}),"\n",(0,r.jsx)(n.li,{children:"Periodic logging to reduce output spam (every 10th message)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Physics Insight"}),": During freefall, robot experiences weightlessness (near-zero acceleration); impact creates 2-3g spikes"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"practice-exercises",children:"Practice Exercises"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Balance Strategy Analysis"}),": Given IMU data stream with roll/pitch angles and forward acceleration, identify when to apply ankle/hip/stepping strategies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AI Colearning Prompt"}),": Explain sensor fusion combining accelerometer, gyroscope, and magnetometer for drift-free orientation estimation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fall Detection Challenge"}),": Calculate angular velocity (rate of pitch change) between samples; predict time until robot falls if trend continues"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"common-pitfalls-expert-insights",children:"Common Pitfalls (Expert Insights)"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Skipping IMU Calibration"}),": Gyroscope bias must be measured at startup while robot is stationary; magnetometer needs full rotation mapping. Skipping calibration = immediate orientation errors and falling."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ignoring Covariance Matrices"}),": sensor_msgs/Imu covariance indicates measurement confidence. Production systems monitor covariance; sudden spikes trigger safe mode rather than trusting bad data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Single-Sensor Reliance"}),": No single IMU sensor is reliable enough for critical balance. Sensor fusion (IMU + vision + encoders) creates robust systems tolerating individual faults."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"assessment-criteria",children:"Assessment Criteria"}),"\n",(0,r.jsx)(n.p,{children:"Students demonstrate mastery when they can:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Explain accelerometer, gyroscope, magnetometer measurement principles and error characteristics (drift, noise, interference)"}),"\n",(0,r.jsx)(n.li,{children:"Differentiate IMU sensor performance: consumer-grade (0.1-1\xb0/hr drift), tactical-grade (1-3\xb0/hr), navigation-grade (<0.01\xb0/hr)"}),"\n",(0,r.jsx)(n.li,{children:"Subscribe to sensor_msgs/Imu topics and extract orientation quaternions, angular velocity, linear acceleration"}),"\n",(0,r.jsx)(n.li,{children:"Convert quaternions to Euler angles (roll, pitch, yaw) using trigonometric formulas"}),"\n",(0,r.jsx)(n.li,{children:"Implement threshold-based detection algorithms (balance monitoring, fall detection) with state tracking"}),"\n",(0,r.jsx)(n.li,{children:"Design multi-stage balance control systems (ankle, hip, stepping strategies) with justified thresholds"}),"\n",(0,r.jsx)(n.li,{children:"Explain proprioception as IMU + joint encoders for complete body state awareness"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Module 1: ROS2 Basics (nodes, topics, publishers, subscribers, message types, callbacks)"}),"\n",(0,r.jsx)(n.li,{children:"Lesson 1: Camera Systems (sensor_msgs/Image, CameraInfo, camera types)"}),"\n",(0,r.jsx)(n.li,{children:"Lesson 2: Depth Sensing (sensor_msgs/LaserScan, PointCloud2, LiDAR principles)"}),"\n",(0,r.jsx)(n.li,{children:"Python 3.11+ with type hints, numpy for array/vector operations"}),"\n",(0,r.jsx)(n.li,{children:"Basic physics: acceleration, angular velocity, gravity, coordinate systems"}),"\n",(0,r.jsx)(n.li,{children:"Linear algebra: vectors, quaternions (basic understanding)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lesson 4"}),": Sensor Fusion Techniques (combining IMU, cameras, depth sensors for robust perception)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Connection"}),": IMU provides proprioception but drifts over time; cameras provide exteroception but fail in darkness. Sensor fusion intelligently combines multiple sources to overcome individual limitations, creating production-ready perception systems for real-world humanoid operation."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Concept"}),": Extended Kalman Filter (EKF) and complementary filters for fusing accelerometer (long-term tilt reference), gyroscope (short-term precision), magnetometer (absolute heading), and visual odometry (drift correction)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"metadata",children:"Metadata"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Generated by"}),": Agent Pipeline (9-agent system)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Created"}),": 2025-12-12"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tags"}),": ros2, sensors, imu, proprioception, humanoid-robotics, balance-control"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cognitive Load"}),": Moderate-High (9 new concepts: 3 IMU sensors, quaternions, sensor drift/noise, proprioception, balance loop, 3 balance strategies, covariance matrices)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Word Count"}),": ~3,200 words (excluding code, comprehensive coverage with 3 case studies + 2 code examples)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sections"}),": 8 (What Is, Why Matters, Key Principles [5 subsections], Callouts [3 total], Real-World Examples [3 case studies], 2 Practical Examples, Summary, Next Steps)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"validation-status",children:"Validation Status"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u2705 Technical Review: PASS WITH REVISIONS (critical drift rate correction applied: degree/hour vs degree/second)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Structure & Style: PASS (all 7 sections present, proper heading hierarchy, callout formatting correct)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Frontmatter: COMPLETE (13 fields generated with 5 skills, 5 learning objectives)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Code Quality: PASS (type hints, docstrings, error handling, numpy operations, ROS2 patterns validated)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Case Studies: 3 detailed examples (Atlas FOG IMU, Digit MEMS + sensor fusion, Unitree H1 world record)"}),"\n",(0,r.jsx)(n.li,{children:"\u2705 Callouts: 1 AI Colearning, 1 Expert Insight, 1 Practice Exercise, 3 Case Studies (\ud83d\udcca)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"technical-corrections-applied",children:"Technical Corrections Applied"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gyroscope Drift Rate"}),' (Line 43): Changed from "1 degree per second" to "0.1-1 degree per hour (consumer), 1-3\xb0/hour (tactical), <0.01\xb0/hour (navigation)" - corrected by factor of 3600']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reaction Time Harmonization"})," (Lines 19, 87): Clarified 25-50ms sensor-to-actuation loop, 50-200ms complete corrective movements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Balance Strategy Thresholds"}),' (Line 81): Added "approximately" qualifier to indicate thresholds vary by robot design']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Case Study Qualifiers"}),': Added "estimated ranges based on industry standards" for unverified Digit specifications']}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var i=s(6540);const r={},o=i.createContext(r);function t(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);