"use strict";(globalThis.webpackChunkbook_source=globalThis.webpackChunkbook_source||[]).push([[9725],{2070:o=>{o.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Physical AI & Humanoid Robotics","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals","label":"ROS2 Fundamentals","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals.summary","label":"ROS2 Fundamentals - Summary","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services","label":"Nodes, Topics, and Services","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services.summary","label":"Nodes, Topics, and Services - Summary","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge","label":"Python rclpy Bridge","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge.summary","label":"Python rclpy Bridge - Summary","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics","label":"URDF for Humanoid Robots","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics.summary","label":"URDF for Humanoid Robots - Summary","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project","label":"Capstone Project: Design a Delivery Robot System","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project.summary","label":"Capstone Project: Design a Delivery Robot System - Summary","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/quiz","label":"Module 1 Quiz: The Robotic Nervous System (ROS 2)","docId":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/quiz","unlisted":false}],"href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/ros2-nervous-system/"},{"type":"category","label":"Module 2: Sensors and Perception for Humanoid Robots","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems","label":"Lesson 1: Camera Systems and Computer Vision","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems.summary","label":"Summary: Lesson 1 - Camera Systems and Computer Vision","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing","label":"Lesson 2: Depth Sensing Technologies","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing.summary","label":"Summary: Lesson 2 - Depth Sensing Technologies","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception","label":"IMU & Proprioception","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary","label":"Summary: Lesson 3 - IMU and Proprioception","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion","label":"Sensor Fusion","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion.summary","label":"Lesson 4 Summary: Sensor Fusion Techniques for Humanoid Robots","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.architecture","label":"Multi-Sensor Fusion Capstone: Architecture Documentation","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.architecture","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.casestudies","label":"Case Studies: Real-World Multi-Sensor Integration","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.casestudies","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.content","label":"Module 2 Capstone Project: Integrated Sensor System Design","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.content","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project","label":"Capstone Project: Design a Multi-Sensor Humanoid Perception System","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.summary","label":"Capstone Summary","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/quiz","label":"Module 2 Quiz: Sensors and Perception for Humanoid Robots","docId":"Physical-AI-Humanoid-Robotics/sensors-perception/quiz","unlisted":false}],"href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/sensors-perception/"},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation","label":"Isaac Sim for Photorealistic Simulation","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation.summary","label":"Isaac Sim for Photorealistic Simulation - Summary","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception","label":"Isaac ROS Hardware-Accelerated Perception","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception.summary","label":"Isaac ROS Hardware-Accelerated Perception - Summary","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning","label":"Nav2 Path Planning for Bipedal Humanoids","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning.summary","label":"Nav2 Path Planning for Bipedal Humanoids - Summary","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation","label":"Integration: Autonomous Navigation System","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation.summary","label":"Integration: Autonomous Navigation System - Summary","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project","label":"Capstone Project: Design Complete Autonomous Humanoid System","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project.summary","label":"Capstone Project: Design Complete Autonomous Humanoid System - Summary","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/quiz","label":"Module 3 Quiz: The AI-Robot Brain (NVIDIA Isaac\u2122)","docId":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/quiz","unlisted":false}],"href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/isaac-ai-brain/"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action","label":"Lesson 1 - Voice-to-Action Systems","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action.summary","label":"Summary - Lesson 1 - Voice-to-Action Systems","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning","label":"Lesson 2 - Cognitive Planning with LLMs","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning.summary","label":"Summary - Lesson 2 - Cognitive Planning with LLMs","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration","label":"Lesson 3 - Vision-Language Integration","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration.summary","label":"Summary - Lesson 3 - Vision-Language Integration","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control","label":"Lesson 4 - Action Execution and Control","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control.summary","label":"Summary - Lesson 4 - Action Execution and Control","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project","label":"Capstone Project - The Autonomous Humanoid","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project.summary","label":"Summary - Capstone Project - The Autonomous Humanoid","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project.summary","unlisted":false},{"type":"link","href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/quiz","label":"Module 4 Quiz - Vision-Language-Action (VLA)","docId":"Physical-AI-Humanoid-Robotics/vision-language-action/quiz","unlisted":false}],"href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/vision-language-action/"}],"href":"/hackathon-phase-01/docs/Physical-AI-Humanoid-Robotics/"}]},"docs":{"Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project","title":"Capstone Project: Design Complete Autonomous Humanoid System","description":"Project Overview","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project.summary":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/capstone-project.summary","title":"Capstone Project: Design Complete Autonomous Humanoid System - Summary","description":"Quick Reference: Key concepts from the capstone project integrating all Isaac platform components","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation","title":"Integration: Autonomous Navigation System","description":"The true power of the NVIDIA Isaac platform emerges when Isaac Sim, Isaac ROS, and Nav2 work together as an integrated autonomous navigation system. This integration creates a complete pipeline from simulation and training through real-time perception and navigation, enabling humanoid robots to operate autonomously in complex environments. Understanding how these components connect and exchange information is essential for designing effective autonomous systems.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation.summary":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/integration-autonomous-navigation.summary","title":"Integration: Autonomous Navigation System - Summary","description":"Quick Reference: Key concepts from Isaac platform integration lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception","title":"Isaac ROS Hardware-Accelerated Perception","description":"Isaac ROS brings NVIDIA\'s GPU acceleration to the Robot Operating System (ROS2), enabling real-time perception capabilities that are essential for humanoid robot autonomy. Through specialized GPU-accelerated libraries called GEMs (GPU-accelerated modules), Isaac ROS dramatically improves the performance of computationally intensive perception tasks like Visual SLAM, object detection, and pose estimation. For humanoid robots that require rapid processing of sensor data to maintain balance and navigate safely, Isaac ROS provides the performance necessary for real-time operation.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception.summary":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-ros-perception.summary","title":"Isaac ROS Hardware-Accelerated Perception - Summary","description":"Quick Reference: Key concepts from Isaac ROS perception lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation","title":"Isaac Sim for Photorealistic Simulation","description":"Isaac Sim is NVIDIA\'s advanced robotics simulation environment built on the Omniverse platform. It provides photorealistic rendering capabilities that enable roboticists to train and test robots in virtual worlds that closely match real-world conditions. For humanoid robots, Isaac Sim offers the ability to generate unlimited synthetic sensor data, test navigation and manipulation tasks safely, and experiment with different environmental conditions without physical hardware.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation.summary":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/isaac-sim-simulation.summary","title":"Isaac Sim for Photorealistic Simulation - Summary","description":"Quick Reference: Key concepts from Isaac Sim simulation lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning","title":"Nav2 Path Planning for Bipedal Humanoids","description":"Navigation2 (Nav2) is ROS2\'s standard navigation framework that provides path planning, obstacle avoidance, and goal-based navigation for mobile robots. For humanoid robots, Nav2 requires specialized configurations and extensions to accommodate the unique constraints of bipedal locomotion, including footstep planning, center-of-mass stability, and gait-specific movement patterns. Unlike wheeled robots that can move continuously in any direction, humanoid robots must plan discrete foot placements while maintaining balance throughout the navigation process.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning.summary":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/nav2-path-planning.summary","title":"Nav2 Path Planning for Bipedal Humanoids - Summary","description":"Quick Reference: Key concepts from Nav2 humanoid navigation lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/quiz":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/quiz","title":"Module 3 Quiz: The AI-Robot Brain (NVIDIA Isaac\u2122)","description":"Instructions","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/isaac-ai-brain/README":{"id":"Physical-AI-Humanoid-Robotics/isaac-ai-brain/README","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","description":"Focus: Advanced perception and navigation for humanoid robots using the NVIDIA Isaac platform.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/README":{"id":"Physical-AI-Humanoid-Robotics/README","title":"Physical AI & Humanoid Robotics","description":"Welcome to the Physical AI & Humanoid Robotics learning path! This chapter explores the fundamental technologies powering humanoid robots and physical AI systems.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project","title":"Capstone Project: Design a Delivery Robot System","description":"Integrative project combining ROS2 architecture, node communication patterns, Python rclpy code, and URDF robot modeling to design a complete autonomous delivery robot system.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project.summary":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/capstone-project.summary","title":"Capstone Project: Design a Delivery Robot System - Summary","description":"Quick Reference: Integrative project overview","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services","title":"Nodes, Topics, and Services","description":"Learn how ROS2 nodes communicate through topics (pub/sub) and services (request/response), and understand when to use each communication pattern for coordinating robot behaviors.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services.summary":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/nodes-topics-services.summary","title":"Nodes, Topics, and Services - Summary","description":"Quick Reference: Key concepts from this lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge","title":"Python rclpy Bridge","description":"Learn how to connect Python programming to ROS2 using the rclpy library, creating nodes, publishers, and subscribers to bring robot communication patterns to life in actual code.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge.summary":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/python-rclpy-bridge.summary","title":"Python rclpy Bridge - Summary","description":"Quick Reference: Key concepts from this lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/quiz":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/quiz","title":"Module 1 Quiz: The Robotic Nervous System (ROS 2)","description":"Assessment quiz covering ROS2 fundamentals, node communication, Python rclpy, and URDF robot modeling. 15 questions testing comprehension across all four lessons. Passing score: 12/18 points (67%).","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/README":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/README","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"Focus: Middleware for robot control","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals","title":"ROS2 Fundamentals","description":"Learn what ROS2 is, why it\'s essential for humanoid robotics, and how it enables modular, distributed robot systems through nodes, topics, and publish-subscribe communication.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals.summary":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/ros2-fundamentals.summary","title":"ROS2 Fundamentals - Summary","description":"Quick Reference: Key concepts from this lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics","title":"URDF for Humanoid Robots","description":"Learn how robots are described structurally using URDF (Unified Robot Description Format) to define humanoid robot bodies, joints, and links for simulation, visualization, and motion planning.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics.summary":{"id":"Physical-AI-Humanoid-Robotics/ros2-nervous-system/urdf-humanoid-basics.summary","title":"URDF for Humanoid Robots - Summary","description":"Quick Reference: Key concepts from this lesson","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems","title":"Lesson 1: Camera Systems and Computer Vision","description":"What Is a Camera in Robotics?","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems.summary":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/camera-systems.summary","title":"Summary: Lesson 1 - Camera Systems and Computer Vision","description":"Module: Module 2 - Sensors and Perception for Humanoid Robots","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project","title":"Capstone Project: Design a Multi-Sensor Humanoid Perception System","description":"Integrative project combining camera systems, depth sensing, IMU integration, and sensor fusion to design a complete perception system for a humanoid warehouse robot.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.architecture":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.architecture","title":"Multi-Sensor Fusion Capstone: Architecture Documentation","description":"System Architecture Overview","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.casestudies":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.casestudies","title":"Case Studies: Real-World Multi-Sensor Integration","description":"These case studies showcase how leading humanoid robots integrate camera systems, depth sensors, IMUs, and sensor fusion to solve real-world challenges. Use these examples as design inspiration for your capstone project, not as blueprints to copy. Each robot made specific trade-offs based on their operational requirements, cost constraints, and technical priorities.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.content":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.content","title":"Module 2 Capstone Project: Integrated Sensor System Design","description":"Introduction","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.summary":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/capstone-project.summary","title":"Module 2 Capstone Summary: Integrated Sensor System Design","description":"Key takeaways and summary of the integrated sensor system design capstone project for humanoid robots.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing","title":"Lesson 2: Depth Sensing Technologies","description":"What Is Depth Sensing in Robotics?","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing.summary":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/depth-sensing.summary","title":"Summary: Lesson 2 - Depth Sensing Technologies","description":"Module: Module 2 - Sensors and Perception for Humanoid Robots","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception","title":"Lesson 3: IMU and Proprioception for Humanoid Robots","description":"Learn how inertial measurement units and proprioceptive sensors enable humanoid robots to sense their own motion, orientation, and body position for dynamic balance control and spatial self-awareness.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/imu-proprioception.summary","title":"Summary: Lesson 3 - IMU and Proprioception","description":"Module: Module 2 - Sensors and Perception for Humanoid Robots","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/quiz":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/quiz","title":"Module 2 Quiz: Sensors and Perception for Humanoid Robots","description":"Assessment quiz covering camera systems, depth sensing, IMU sensors, and sensor fusion for humanoid robots. 15 questions testing comprehension across all four lessons. Passing score: 12/18 points (67%).","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/README":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/README","title":"Module 2: Sensors and Perception for Humanoid Robots","description":"Focus: How humanoid robots sense and understand their environment","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion","title":"Lesson 4: Sensor Fusion Techniques for Humanoid Robots","description":"Learn how sensor fusion combines camera, depth, and IMU data to create robust perception systems that overcome individual sensor limitations through complementary filtering, Kalman filtering, and Visual-Inertial Odometry.","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion.summary":{"id":"Physical-AI-Humanoid-Robotics/sensors-perception/sensor-fusion.summary","title":"Lesson 4 Summary: Sensor Fusion Techniques for Humanoid Robots","description":"Learning Outcomes","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control","title":"Lesson 4 - Action Execution and Control","description":"What Is VLA Action Execution?","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control.summary":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/action-execution-control.summary","title":"Summary - Lesson 4 - Action Execution and Control","description":"Module: Module 4 - Vision-Language-Action (VLA)","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project","title":"Capstone Project - The Autonomous Humanoid","description":"Project Overview","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project.summary":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/capstone-project.summary","title":"Summary - Capstone Project - The Autonomous Humanoid","description":"Module: Module 4 - Vision-Language-Action (VLA)","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning","title":"Lesson 2 - Cognitive Planning with LLMs","description":"What Is Cognitive Planning?","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning.summary":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/cognitive-planning.summary","title":"Summary - Lesson 2 - Cognitive Planning with LLMs","description":"Module: Module 4 - Vision-Language-Action (VLA)","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/quiz":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/quiz","title":"Module 4 Quiz - Vision-Language-Action (VLA)","description":"Instructions","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/README":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/README","title":"Module 4: Vision-Language-Action (VLA)","description":"Overview","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration","title":"Lesson 3 - Vision-Language Integration","description":"What Is Vision-Language Integration?","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration.summary":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/vision-language-integration.summary","title":"Summary - Lesson 3 - Vision-Language Integration","description":"Module: Module 4 - Vision-Language-Action (VLA)","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action","title":"Lesson 1 - Voice-to-Action Systems","description":"What Is Voice-to-Action?","sidebar":"tutorialSidebar"},"Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action.summary":{"id":"Physical-AI-Humanoid-Robotics/vision-language-action/voice-to-action.summary","title":"Summary - Lesson 1 - Voice-to-Action Systems","description":"Module: Module 4 - Vision-Language-Action (VLA)","sidebar":"tutorialSidebar"}}}}')}}]);